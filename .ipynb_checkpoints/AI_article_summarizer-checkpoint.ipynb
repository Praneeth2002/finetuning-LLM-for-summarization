{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b773fd6",
   "metadata": {},
   "source": [
    "# AI 574 Final Project\n",
    "## Article Summarization fine tuned for articles about deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17b52af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87d797aa",
   "metadata": {},
   "source": [
    "# Section 1:  Define and use functions to retrieve and parse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3704d2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aec653e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need a function that walks through the full directory and finds all of the xml files.\n",
    "#  This function isn't too hard.  Provided with a root directory, it creates a blank list and then \n",
    "#  walks down the subdirectories.  Every time it finds an xml file, it adds it to the list.\n",
    "def list_xml_files(directory):\n",
    "    xml_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.xml'):\n",
    "                xml_files.append(os.path.join(root, file))\n",
    "    return xml_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a12b9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we start defining functions to parse the XML file itsself.  For every header at level one that we find \n",
    "#  within the XML file, we need to pull it's title.  The ABSTRACT seems to pull out correctly, but for any further\n",
    "#  major sections in the paper, the attribute of \"title\" ends up holding the title of the section.  As such, we use\n",
    "#  the element tag to hold the section title if it doesn't have a specific title.  If it does, then the title is held.\n",
    "#  This function creates a list of the data for the entire paper.  Specifically, if the depth of the XML tree is at 1, it\n",
    "#  iterates through the children of this tree and pulls out all of the text from the file.  This is then appended to a list\n",
    "#  to store all of the data.\n",
    "\n",
    "def parse_element(element, depth = 0):\n",
    "    data = []\n",
    "    \n",
    "    if depth == 1 :\n",
    "        if element.tag == 'SECTION':\n",
    "            header = element.attrib.get('title')\n",
    "        else:\n",
    "            header = element.tag\n",
    "        content = []\n",
    "        \n",
    "        for child in element:\n",
    "            content.append(child.text.strip() if child.text else '')\n",
    "        \n",
    "        if content:\n",
    "            data.append((header, '\\n'.join(content)))\n",
    "    \n",
    "    for child in element:\n",
    "        data.extend(parse_element(child, depth + 1))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d8f865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to use the prse_element function, we need to retrieve the file from the tree\n",
    "# and then apply the parsing function to the root retrieved from the path to that paper\n",
    "\n",
    "def parse_xml_file(file_path):\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    return parse_element(root, depth = 0)\n",
    "\n",
    "#  For each of these we also need to read a text file\n",
    "def read_text_file(file_path):\n",
    "    with open(file_path, 'r', encoding = 'utf-8') as file:\n",
    "        return file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2178b3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we need to join all of the section headers and text into a single text item.\n",
    "#  This item will fill our dictionary text item for the articles that we are training from.\n",
    "\n",
    "def format_to_text(data):\n",
    "    formatted_text = []\n",
    "    \n",
    "    for header, content in data:\n",
    "        formatted_text.append(header)\n",
    "        formatted_text.append(content)\n",
    "    return '\\n\\n'.join(formatted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3bd9831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(xml_file_path):\n",
    "    base_path = os.path.dirname(xml_file_path)\n",
    "    xml_file_name = os.path.basename(xml_file_path).replace('.xml', '')\n",
    "    summary_file_path = os.path.join(base_path, '..', 'summary', f'{xml_file_name}.gold.txt')\n",
    "    \n",
    "    xml_data = parse_xml_file(xml_file)\n",
    "    document_text = format_to_text(xml_data)\n",
    "    \n",
    "    summary_text = read_text_file(summary_file_path)\n",
    "    \n",
    "    lines = summary_text.split('\\n', 1)\n",
    "    title = lines[0].strip() if lines else ''\n",
    "    summary = lines[1].strip() if len(lines) > 1 else ''\n",
    "    \n",
    "    results = {\n",
    "        'text': document_text,\n",
    "        'summary': summary,\n",
    "        'title': title\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4df620",
   "metadata": {},
   "source": [
    "## Reading the documents:\n",
    "There are 1009 documents in our sample dataset, so we need to generate a list of the files that store those documents.  \n",
    "This code will generate a list of the links to the xml files.  These file names are then used to track down the summaries as well with the functions presented above.  In the end, we end up with a list of dictionary items containing the text, summary, and title for each article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3c08ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"top1000_complete\"\n",
    "xml_files = list_xml_files(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffa428c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1009\n"
     ]
    }
   ],
   "source": [
    "print(len(xml_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3a39209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'top1000_complete\\\\A00-1043\\\\Documents_xml\\\\A00-1043.xml'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_files[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ec633f",
   "metadata": {},
   "source": [
    "#### An example of a single paper in order to make sure that the above code works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd4f0a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read_files(xml_files[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d175fa97",
   "metadata": {},
   "source": [
    "###  Reading all the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b7810be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for xml_file in xml_files:\n",
    "    file = read_files(xml_file)\n",
    "    data.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22bafd2",
   "metadata": {},
   "source": [
    "Our data is now in a list of dictionaries which matches the billsum dataset within the tutorial provided by huggingface at https://huggingface.co/docs/transformers/v4.17.0/en/tasks/summarization\n",
    "\n",
    "Based on this, we should be able to fine tune our model.  One quick step that we should take will be to convert our dataset into the right format and then apply a splitting to the data in order to test the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f788fdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b3da464",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_dict({\n",
    "    'text': [item['text'] for item in data],\n",
    "    'summary': [item['summary'] for item in data],\n",
    "    'title': [item['title'] for item in data]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33b7e5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_temp, test_data = dataset.train_test_split(test_size = 0.15, seed = 42).values()\n",
    "train_data, valid_data = train_data_temp.train_test_split(test_size = 0.176, seed = 42).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "130e50d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = DatasetDict({\n",
    "    'train': train_data,\n",
    "    'valid': valid_data,\n",
    "    'test': test_data\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b989fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the data is working properly...\n",
    "\n",
    "#data_dict['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83ef0601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.dataset_dict.DatasetDict"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feef0cd4",
   "metadata": {},
   "source": [
    "## Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1695f2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39d87f16",
   "metadata": {},
   "source": [
    "# Section 2:  Fine Tuning Model Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c385a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, DataCollatorForSeq2Seq \n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "import evaluate\n",
    "import datasets\n",
    "import rouge_score\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6be96cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 4060 Laptop GPU'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35b3b161",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"google-t5/t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdd1fede",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"summarize: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length = 1024, truncation = True)\n",
    "    labels = tokenizer(text_target = examples[\"summary\"], max_length = 256, truncation = True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bbeffc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d97e8e70bb4f4cce801dff75e7a52824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/706 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c306ad12e7f4e1aa474852f64b2b8d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/151 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b7dd9b8518443d3ac0e2d8d707b7cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/152 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_data = data_dict.map(preprocess_function, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7fa3efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer, model=checkpoint, return_tensors = 'pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22f1a487",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f0231a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens = True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens = True)\n",
    "    result = rouge.compute(predictions = decoded_preds, references = decoded_labels, use_stemmer = True)\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    return {k: round(v, 4) for k, v, in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65243b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
    "model.generation_config.max_new_tokens = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c38551b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    num_train_epochs = 3,\n",
    "    \n",
    "    per_device_train_batch_size = 16,\n",
    "    per_device_eval_batch_size = 16,\n",
    "    \n",
    "    output_dir = \"T5_model\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    learning_rate = 2e-5,\n",
    "    weight_decay = 0.01,\n",
    "    \n",
    "    save_total_limit = 1,\n",
    "    predict_with_generate = True,\n",
    "    fp16 = True,\n",
    "    push_to_hub = False,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_data[\"train\"],\n",
    "    eval_dataset = tokenized_data[\"valid\"],\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = data_collator,\n",
    "    compute_metrics = compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f4d7099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(mode='disabled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5396e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='135' max='135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [135/135 22:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.211576</td>\n",
       "      <td>0.386600</td>\n",
       "      <td>0.285600</td>\n",
       "      <td>0.335100</td>\n",
       "      <td>0.334600</td>\n",
       "      <td>77.973500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.872245</td>\n",
       "      <td>0.452600</td>\n",
       "      <td>0.377500</td>\n",
       "      <td>0.417100</td>\n",
       "      <td>0.417300</td>\n",
       "      <td>88.291400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.803907</td>\n",
       "      <td>0.467900</td>\n",
       "      <td>0.382200</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.426000</td>\n",
       "      <td>95.894000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=135, training_loss=2.7915106879340277, metrics={'train_runtime': 1340.2777, 'train_samples_per_second': 1.58, 'train_steps_per_second': 0.101, 'total_flos': 573307871035392.0, 'train_loss': 2.7915106879340277, 'epoch': 3.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "096d2374",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory=\"./T5_model\"\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "trainer.save_model(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a481ccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"./T5_model\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"./T5_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "460ecd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'summary', 'title', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 152\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "57952646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summaries(inputs):\n",
    "    inputs = tokenizer(inputs, return_tensors='pt', padding = True, truncation = True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(inputs['input_ids'], max_new_tokens = 256, min_new_tokens = 200, num_beams = 4, early_stopping = True)\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0eff0192",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_texts = []\n",
    "for example in tokenized_data['test']:\n",
    "    input_text = example['text']\n",
    "    prediction = generate_summaries(input_text)\n",
    "    generated_texts.append(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d41c01b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_summaries = [example['summary'] for example in data_dict['test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dcd7951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rouge.compute(predictions = generated_texts, references = true_summaries, use_stemmer = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f7048805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.4734873877453236, 'rouge2': 0.3105911842862591, 'rougeL': 0.3427332448323207, 'rougeLsum': 0.4374135455571472}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9fe4ae7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s exploit complicated data structures, such as typed feature structures. This article proposes the feature forest model as a solution to the problem of probabilistic modeling of complex data structures including typed feature structures. This article proposes the feature forest model as a solution to the problem of probabilistic modeling of complex data structures including typed feature structures. This article proposes the feature forest model as a solution to the problem of probabilistic modeling of complex data structures including typed feature structures. This article proposes the feature forest model as a solution to lexicalized grammars, such as typed feature structures. These methods have relied on the structure of the target problem, namely lattices or trees, as a solution to the problem of lexicalized grammars. This article also describes methods for representing HPSG syntactic structures and predicate–argument structures. This article proposes the feature forest model as a solution to the problem of probabilistic modeling of lexicalized grammars. This article proposes the feature forest model as a solution to the problem of lexicalized grammars. This article proposes the feature forest model as a solution to the problem of'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_texts[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "21d79df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Probabilistic modeling of lexicalized grammars is difficult because these grammars exploit complicated data structures, such as typed feature structures.\\nThis prevents us from applying common methods of probabilistic modeling in which a complete structure is divided into substructures under the assumption of statistical independence among sub-structures.\\nFor example, part-of-speech tagging of a sentence is decomposed into tagging of each word, and CFG parsing is split into applications of CFG rules.\\nThese methods have relied on the structure of the target problem, namely lattices or trees, and cannot be applied to graph structures including typed feature structures.\\nThis article proposes the feature forest model as a solution to the problem of probabilistic modeling of complex data structures including typed feature structures.\\nThe feature forest model provides a method for probabilistic modeling without the independence assumption when probabilistic events are represented with feature forests.\\nFeature forests are generic data structures that represent ambiguous trees in a packed forest structure.\\nFeature forest models are maximum entropy models defined over feature forests.\\nA dynamic programming algorithm is proposed for maximum entropy estimation without unpacking feature forests.\\nThus probabilistic modeling of any data structures is possible when they are represented by feature forests.\\nThis article also describes methods for representing HPSG syntactic structures and predicate–argument structures with feature forests.\\nHence, we describe a complete strategy for developing probabilistic models for HPSG parsing.\\nThe effectiveness of the proposed methods is empirically evaluated through parsing experiments on the Penn Treebank, and the promise of applicability to parsing of real-world sentences is discussed.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_summaries[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527d2989",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
